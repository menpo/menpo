{
 "metadata": {
  "name": "Basic Lucas-Kanade"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Basic Lucas-Kanade"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Load the Takeo image from the data directory using the auto importer."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pybug.io import auto_import\n",
      "\n",
      "takeo = auto_import('../data/takeo.ppm')[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The Takeo image is grayscale, so we just get the first channel's pixels to work on. It should also be noted that image is imported as ``uint8`` and thus we must cast to ``float64`` so that integer division is *not* performed."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import matplotlib.pyplot as plt\n",
      "import matplotlib.cm as cm\n",
      "import numpy as np\n",
      "\n",
      "image = np.array(takeo.pixels[:,:,0], dtype=np.float64)\n",
      "plt.imshow(image, cmap=cm.Greys_r)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Since Lucas-Kanade involves matching images between a template and an input, we begin by creating a template to match to. Therefore, we import a warping function and warp the original image to create a template. Create the warp involves defining a set of initial warp parameters, which we will attempt to recover using the Lucas-Kanade algorithm. The warp parameters are defined as the elements of the transform matrix that transforms from target to source. We honour the parameter layout specified in the Lucas-Kanade 20 years on paper:\n",
      "\\centering\n",
      "\\begin{pmatrix}\n",
      "p1 & p3 & p5\\\\\n",
      "p2 & p4 & p6\n",
      "\\end{pmatrix}\n",
      "\n",
      "where $p5$ and $p6$ are the translation parameters."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pybug.warp import warp\n",
      "from pybug.transform import AffineTransform\n",
      "\n",
      "target_params = np.array([0, 0.1, 0.2, 0, 30, 70])\n",
      "target_shape = (90, 90)\n",
      "\n",
      "template = warp(image, target_shape, AffineTransform.from_parameters(target_params))\n",
      "plt.imshow(template, cmap=cm.Greys_r)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In order to perform the alignment, we seperate the algorithm from the similarity measure used. Therefore, we begin by creating a similarity measure which defines how we define the error between the two images. For this example, we use the most simple case, the LeastSquares pixels differences."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pybug.align.lucaskanade.similaritymeasure import LeastSquares, ECC\n",
      "\n",
      "sim_measure = LeastSquares()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, given an initial estimate, we can perform the alignment. We can either perform an inverse compositional alignment, or a forward additive. Lucas-Kanade is a gradient descent algorithm, and thus assumes a near global optimum initial parameterisaton. We therefore begin by initialising the image to roughly Takeo's face."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pybug.align.lucaskanade import InverseCompositional, ForwardAdditive\n",
      "\n",
      "initial_params = np.array([0, 0, 0, 0, 30.5, 70.5])\n",
      "\n",
      "inv_comp = InverseCompositional(image, template, sim_measure, AffineTransform.from_parameters(initial_params))\n",
      "for_add = ForwardAdditive(image, template, sim_measure, AffineTransform.from_parameters(initial_params))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We then perform the alignment, and show the resulting transforms."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Set Figure to be larger\n",
      "fig = matplotlib.pyplot.gcf()\n",
      "fig.set_size_inches(12.0, 5.0)\n",
      "\n",
      "# Get Inverse Compositional parameters and plot\n",
      "inv_comp_transform = inv_comp.align()\n",
      "inv_comp_params = inv_comp_transform.parameters\n",
      "\n",
      "inv_comp_match = warp(image, target_shape, AffineTransform.from_parameters(inv_comp_params))\n",
      "ax = subplot(1,3,2)\n",
      "ax.set_title('Inverse Compositional')\n",
      "plt.imshow(inv_comp_match, cmap=cm.Greys_r)\n",
      "\n",
      "# Get Forward Additive parameters and plot\n",
      "for_add_transform = for_add.align()\n",
      "for_add_params = for_add_transform.parameters\n",
      "\n",
      "for_add_match = warp(image, target_shape, AffineTransform.from_parameters(for_add_params))\n",
      "ax = subplot(1,3,3)\n",
      "ax.set_title('Forward Additive')\n",
      "plt.imshow(for_add_match, cmap=cm.Greys_r)\n",
      "\n",
      "# Plot original\n",
      "template = warp(image, target_shape, AffineTransform.from_parameters(target_params))\n",
      "ax = subplot(1,3,1)\n",
      "ax.set_title('Original')\n",
      "plt.imshow(template, cmap=cm.Greys_r)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can then compute the RMS point error between the original bounding box and the one proposed by our alignment algorithms. Usually, any error less than 3 pixels is considered a convergence."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def compute_rms_point_error(test_pts, template_affine, M):\n",
      "    iteration_pts = M.apply(template_affine.T)\n",
      "    diff_pts = test_pts - iteration_pts\n",
      "    return np.sqrt(np.mean(diff_pts ** 2))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "target_transform = AffineTransform.from_parameters(target_params)\n",
      "original_box = np.array([[0, 0],\n",
      "                         [90, 0],\n",
      "                         [90, 90],\n",
      "                         [0, 90]]).T\n",
      "target_pts = target_transform.apply(original_box.T)\n",
      "print 'Inverse compositional RMS error: {0}'.format(compute_rms_point_error(target_pts, original_box, inv_comp_transform))\n",
      "print 'Forward additive RMS error:      {0}'.format(compute_rms_point_error(target_pts, original_box, for_add_transform))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}