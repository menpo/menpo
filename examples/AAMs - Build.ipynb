{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Active Appearance Models Notebook\n",
      "##### Version 0.1"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 1. Build an Active Appearance Model (AAM)\n",
      "### 1.1 Load the Data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "-"
      }
     },
     "source": [
      "We use the *autoimporter* to load the **annotated** *training images* of the **Labelled Faces Parts in the Wild (LFPW)** dataset."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pybug.io import auto_import\n",
      "from pybug.landmark.labels import ibug_68_points, ibug_68_contour, ibug_68_trimesh, labeller\n",
      "\n",
      "# load the training images of the LFPW database as landmarked images using the autoimporter\n",
      "images = auto_import('/vol/atlas/databases/lfpw/train/' + '*.png')\n",
      "\n",
      "# label the landmarks using the ibug's \"standard\" 68 points mark-up\n",
      "labeller(images, 'PTS', ibug_68_points)\n",
      "labeller(images, 'PTS', ibug_68_contour)\n",
      "labeller(images, 'PTS', ibug_68_trimesh)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "img = images[0]\n",
      "\n",
      "# visualize the first image\n",
      "img.view()\n",
      "img.get_landmark_set('ibug_68_points').view()\n",
      "img.get_landmark_set('ibug_68_contour').view()\n",
      "img.get_landmark_set('ibug_68_trimesh').view()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We have now loaded enough data to create a meaninful **Active Appearance Model (AAM)** from the LFPW database."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 2. Build the Template Frame\n",
      "\n",
      "We will start by centereing all landmarks around the origin (0,0)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pybug.shape import PointCloud\n",
      "\n",
      "points = [img.landmarks['PTS'].all_landmarks.points - 1  for img in images]\n",
      "shapes = [PointCloud(p) for p in points]\n",
      "\n",
      "centralized_points = [p - np.mean(p, axis=0) for p in points]\n",
      "centralized_shapes = [PointCloud(p) for p in points]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can visualy check that indeed they are now centered."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "centralized_shapes[0].view()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "No we will normalize them up to a similarity transform by performing Procrustes Analysis."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pybug.align import GeneralizedProcrustesAnalysis\n",
      "\n",
      "gpa = GeneralizedProcrustesAnalysis(centralized_points)\n",
      "aligned_points = [p[-1].aligned_source for p in gpa.procrustes]\n",
      "aligned_shapes = [PointCloud(p) for p in aligned_points]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In order to define the template frame, we will need a function that checks if a particular point is inside a given convex polygon. We define this function."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# this function was obtained from \"http://www.ariel.com.au/a/python-point-int-poly.html\" from the time being\n",
      "def point_inside_polygon(x,y,poly):\n",
      "   \n",
      "    n = len(poly)\n",
      "    inside =False\n",
      "    \n",
      "    p1x,p1y = poly[0]\n",
      "    for i in range(n+1):\n",
      "        p2x,p2y = poly[i % n]\n",
      "        if y > min(p1y,p2y):\n",
      "            if y <= max(p1y,p2y):\n",
      "                if x <= max(p1x,p2x):\n",
      "                    if p1y != p2y:\n",
      "                        xinters = (y-p1y)*(p2x-p1x)/(p2y-p1y)+p1x\n",
      "                    if p1x == p2x or x <= xinters:\n",
      "                        inside = not inside\n",
      "        p1x,p1y = p2x,p2y\n",
      "    \n",
      "    return inside"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Define template frame."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pybug.image.base import Image\n",
      "\n",
      "mean_points = np.mean(aligned_points, axis=0)\n",
      "margin = 3\n",
      "template_landmarks = PointCloud(mean_points - np.min(mean_points, axis=0) + margin)\n",
      "\n",
      "# the resolution of the template is typically related to the size of the mean shape\n",
      "scale = 1\n",
      "template_resolution = scale * np.ceil(np.max(template_landmarks.points, axis=0) + margin)\n",
      "\n",
      "template_data = np.zeros(template_resolution)\n",
      "\n",
      "# this looks a bit overcomplicated for what I end up doing... \n",
      "template_landmarks.add_landmark_set('PTS', {'all': template_landmarks})\n",
      "labeller([template_landmarks], 'PTS', ibug_68_contour)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pybug.image.base import MaskImage\n",
      "\n",
      "# same here...\n",
      "convex_hull = template_landmarks.get_landmark_set('ibug_68_contour').all_landmarks.points\n",
      "plot(convex_hull[:,0],convex_hull[:,1])\n",
      "\n",
      "y = np.arange(template_resolution[1], dtype=np.int)\n",
      "x = np.arange(template_resolution[0],  dtype=np.int)\n",
      "yv, xv = np.meshgrid(y, x)\n",
      "\n",
      "mask_data = np.zeros(template_resolution, dtype=np.bool)\n",
      "\n",
      "for p in np.array([yv.flatten(), xv.flatten()]).T:\n",
      "    mask_data[p[1],p[0]] = point_inside_polygon(p[1], p[0], convex_hull)\n",
      "    \n",
      "mask = MaskImage(mask_data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pybug.image.base import Image\n",
      "\n",
      "template = Image(template_data, mask=mask)\n",
      "\n",
      "template.add_landmark_set('PTS', {'all': template_landmarks})\n",
      "labeller([template], 'PTS', ibug_68_points)\n",
      "labeller([template], 'PTS', ibug_68_contour)\n",
      "labeller([template], 'PTS', ibug_68_trimesh)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "template.get_landmark_set('ibug_68_points').view()\n",
      "template.get_landmark_set('ibug_68_contour').view()\n",
      "template.get_landmark_set('ibug_68_trimesh').view()\n",
      "\n",
      "#dunno what happens with this...\n",
      "template.mask.view()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def build_template(points, label_func=ibug_68_contour, margin=3, scale=1):\n",
      "    template_landmarks = PointCloud(points - np.min(points, axis=0) + margin)\n",
      "    template_resolution = scale * np.ceil(np.max(template_landmarks.points, axis=0) + margin)\n",
      "    template_data = np.zeros(template_resolution)\n",
      "    y = np.arange(template_resolution[1], dtype=np.int)\n",
      "    x = np.arange(template_resolution[0], dtype=np.int)\n",
      "    yv, xv = np.meshgrid(y, x)\n",
      "    mask_data = np.zeros(template_resolution, dtype=np.bool)\n",
      "    template_landmarks.add_landmark_set('PTS', {'all': template_landmarks})\n",
      "    labeller([template_landmarks], 'PTS', label_func)\n",
      "    convex_hull = template_landmarks.get_landmark_set('ibug_68_contour').all_landmarks.points\n",
      "    plot(convex_hull[:,0],convex_hull[:,1])\n",
      "    for p in np.array([yv.flatten(), xv.flatten()]).T:\n",
      "        mask_data[p[1],p[0]] = point_inside_polygon(p[1], p[0], convex_hull)\n",
      "    mask = MaskImage(mask_data)\n",
      "    template = Image(template_data, mask=mask)\n",
      "    return template, template_landmarks"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 3. Warp the Images\n",
      "\n",
      "The next step consists of *warping* the original LFPW images onto the *reference frame* using the correspondances between their *landmarks* and the *texture coordinates* on the reference frame. We can either use **Piece Wise Affine ** (PWA) or **Thin Plate Spline ** (TPS) for this purpose. The differences between the two families of warps can be observed by visualizing the obtained warped images."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pybug.align.nonrigid.tps import TPS\n",
      "from pybug.transform.piecewiseaffine import PiecewiseAffineTransform\n",
      "from pybug.warp import scipy_warp\n",
      "\n",
      "tps = [TPS(template_landmarks.points, s.points) for s in shapes]\n",
      "tps_warped_images = [scipy_warp(img, template, tps[i].transform) for i,img in enumerate(images)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tps_warped_images[0].view()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 4. Build the Appearance Model\n",
      "The AAM's *appearance model* is typically build by applying **Principal Component Analysis** (PCA) to the previously warped images."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pybug.model.linear import PCAModel\n",
      "\n",
      "# transform all warped images to graysacale\n",
      "grayscale_tps_warped_images = [img.as_greyscale() for img in tps_warped_images] \n",
      "\n",
      "# this would perfectly work in rgb space provided that all original images had rgb color channels (which is not the \n",
      "# case for the LFPW training dataset)\n",
      "tps_appearance_model = PCAModel(grayscale_tps_warped_images, n_components=50)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n_instances = 10\n",
      "appearance_parameters = [np.random.randn(tps_appearance_model.n_components) for i in range(n_instances)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x_axis = range(tps_appearance_model.n_components)\n",
      "cumulative_variance = [np.sum(tps_appearance_model.explained_variance_ratio[:i]) for i in x_axis]\n",
      "\n",
      "tps_appearance_instances = [tps_appearance_model.instance(appearance_parameters[i] * \n",
      "    np.sqrt(tps_appearance_model.explained_variance)) for i in range(n_instances)]\n",
      "\n",
      "subplot(1,2,1)\n",
      "plot(x_axis, cumulative_variance)\n",
      "subplot(1,2,2)\n",
      "tps_appearance_instances[0].view()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 5. Build the Shape Model\n",
      "Similarly, the shape model of the AAM is tipically build by applying PCA to the aligned shapes obtained from GPA. At this point, it is interesting to see the differences between the sets of original, centralized and aligned shapes."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#for s in shapes:\n",
      "#    s.view()\n",
      "#for p in centralized_points:\n",
      "#    PointCloud(p).view()\n",
      "#for s in aligned_shapes:\n",
      "#    s.view()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pybug.model.linear import PCAModel\n",
      "\n",
      "shape_model = PCAModel(aligned_shapes, n_components=3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n_instances = 10\n",
      "shape_parameters = [np.random.randn(shape_model.n_components) for i in range(n_instances)]\n",
      "\n",
      "x_axis = range(shape_model.n_components)\n",
      "cumulative_variance = [np.sum(shape_model.explained_variance_ratio[:i]) for i in x_axis]\n",
      "\n",
      "shape_instances = [shape_model.instance(shape_parameters[i] * np.sqrt(shape_model.explained_variance)) \n",
      "    for i in range(n_instances)]\n",
      "\n",
      "subplot(1,2,1)\n",
      "plot(x_axis, cumulative_variance)\n",
      "subplot(1,2,2)\n",
      "shape_instances[0].view()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 6. Generate an AAM instance"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "i = np.random.randint(n_instances)\n",
      "\n",
      "shape_instance = shape_instances[i]\n",
      "\n",
      "# build a template for the chosen shape instance\n",
      "instance_template, instance_landmarks = build_template(shape_instance.points)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "instance_tps = TPS(instance_landmarks.points, template_landmarks.points)\n",
      "model_tps_instance = scipy_warp(tps_appearance_instances[i], instance_template, instance_tps.transform)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model_tps_instance.view()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 7. Save the AAM"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pickle\n",
      "\n",
      "pickle.dump({'shape_model': shape_model, \n",
      "             'tps_appearance_model': tps_appearance_model,\n",
      "             'template': template,\n",
      "             'template_landmarks': template_landmarks}, open( \"/vol/atlas/aams/aam_lfpw\", \"wb\" ))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}