{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Fit an AAM to an Input Images\n",
      "##### Version 0.1\n",
      "\n",
      "### 1.1 Load the Data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pybug.io import auto_import\n",
      "from pybug.landmark.labels import ibug_68_points, ibug_68_contour, ibug_68_trimesh, labeller\n",
      "\n",
      "# load the training images of the LFPW database as landmarked images using the autoimporter\n",
      "images = auto_import('/vol/atlas/databases/lfpw/train/' + '*.png')\n",
      "\n",
      "# label the landmarks using the ibug's \"standard\" 68 points mark-up\n",
      "labeller(images, 'PTS', ibug_68_points)\n",
      "labeller(images, 'PTS', ibug_68_contour)\n",
      "labeller(images, 'PTS', ibug_68_trimesh)\n",
      "\n",
      "from pybug.shape import PointCloud\n",
      "\n",
      "points = [img.landmarks['PTS'].all_landmarks.points - 1  for img in images]\n",
      "shapes = [PointCloud(p) for p in points]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pickle\n",
      "\n",
      "# load a previously buid AAM\n",
      "aam = pickle.load(open('/vol/atlas/aams/aam_lfpw', \"rb\"))\n",
      "\n",
      "template = aam[\"template\"]\n",
      "template_landmarks = aam[\"template_landmarks\"]\n",
      "tps_appearance_model = aam[\"tps_appearance_model\"]\n",
      "shape_model = aam[\"shape_model\"]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 2.1 Build a Statistically Driven + Similarity Transform "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pybug.model.linear import SimilarityModel\n",
      "\n",
      "test_shape = shapes[85]\n",
      "test_image = images[85].as_greyscale()\n",
      "\n",
      "similarity_model = SimilarityModel(shape_model.mean)\n",
      "\n",
      "similarity_weights = similarity_model.project(test_shape)\n",
      "# remove rotation\n",
      "similarity_weights[1] = 0\n",
      "\n",
      "similarity_transform = similarity_model.equivalent_similarity_transform(similarity_weights)\n",
      "aligned_test_points = similarity_transform.inverse.apply(test_shape.points)\n",
      "aligned_test_shape = PointCloud(aligned_test_points)\n",
      "shape_weights = shape_model.project(aligned_test_shape)\n",
      "\n",
      "initial_weights = np.concatenate([similarity_weights, np.zeros_like(shape_weights)])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pybug.align.nonrigid.tps import TPS\n",
      "from pybug.transform.piecewiseaffine import PiecewiseAffineTransform\n",
      "from pybug.model.linear import SimilarityModel\n",
      "from pybug.transform.statisticallydriven import StatisticallyDrivenPlusSimilarityTransform\n",
      "\n",
      "# function for directly constructing tps transform objects from tps objects\n",
      "def tps_constructor(src_landmarks, tgt_landmarks):\n",
      "    tps = TPS(src_landmarks, tgt_landmarks)\n",
      "    return tps.transform\n",
      "\n",
      "initial_transform = StatisticallyDrivenPlusSimilarityTransform(shape_model,\n",
      "                                                       similarity_model,\n",
      "                                                       tps_constructor,\n",
      "                                                       source=template_landmarks.points,\n",
      "                                                       weights=initial_weights)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pybug.warp import scipy_warp\n",
      "\n",
      "initial_warp = scipy_warp(test_image, template, initial_transform)\n",
      "\n",
      "temp_tps = TPS(template_landmarks.points, test_shape.points)\n",
      "temp = scipy_warp(test_image, template, temp_tps.transform)\n",
      "\n",
      "test_image.add_landmark_set(\"initial\", {\"initial\": PointCloud(initial_transform.target)})\n",
      "test_image.get_landmark_set(\"initial\").view()\n",
      "\n",
      "initial_warp.view()\n",
      "temp.view() "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pybug.align.lucaskanade.residual import LSIntensity\n",
      "from pybug.align.lucaskanade.base import ImageForwardAdditive\n",
      "\n",
      "residual = LSIntensity()\n",
      "project_out = ImageForwardAdditive(test_image, temp, residual, initial_transform)\n",
      "optimal_transform = project_out.align(max_iters=20)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fitted_shape = PointCloud(optimal_transform.target)\n",
      "fitted_appearance = scipy_warp(test_image, template, optimal_transform)\n",
      "\n",
      "test_image.add_landmark_set(\"fitting_result\", {\"fitting_result\": fitted_shape})\n",
      "test_image.get_landmark_set(\"fitting_result\").view()\n",
      "fitted_appearance.view()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}