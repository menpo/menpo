{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Fit an AAM to an Input Images\n",
      "##### Version 0.1\n",
      "\n",
      "### 1. Load the Data\n",
      "\n",
      "Use the **autoimporter** to automatically load the *annotated* test images of the *Labelled Faces Parts in the Wild (LFPW)* dataset."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pybug.io import auto_import\n",
      "from pybug.landmark.labels import  labeller, ibug_68_points, ibug_68_contour, ibug_68_trimesh\n",
      "\n",
      "# load the training images of the LFPW database as landmarked images using the autoimporter\n",
      "images = auto_import('/vol/atlas/databases/lfpw/test/' + '*.png')\n",
      "\n",
      "# label the landmarks using the ibug's \"standard\" 68 points mark-up\n",
      "labeller(images, 'PTS', ibug_68_points)\n",
      "labeller(images, 'PTS', ibug_68_contour)\n",
      "labeller(images, 'PTS', ibug_68_trimesh)\n",
      "\n",
      "from pybug.shape import PointCloud\n",
      "\n",
      "points = [img.landmarks['PTS'].all_landmarks.points - 1  for img in images]\n",
      "shapes = [PointCloud(p) for p in points]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Use **pickle** to load a previously build *AAM*"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pickle\n",
      "\n",
      "# load a previously buid AAM\n",
      "aam = pickle.load(open('/vol/atlas/aams/lfpw_pwa', \"rb\"))\n",
      "\n",
      "reference_frame = aam[\"template\"]\n",
      "appearance_model = aam[\"appearance_model\"]\n",
      "shape_model = aam[\"shape_model_1\"]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 2. Fit\n",
      "\n",
      "We start randomly selecting an image to fit."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# select a test image at random\n",
      "ind = np.random.randint(len(images))\n",
      "test_image = images[ind].as_greyscale()\n",
      "test_shape = shapes[ind]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Then we build a dummy Similarity Transform and a dummy Statistically Driven Transform "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pybug.transform.statisticallydriven import StatisticallyDrivenTransform\n",
      "from pybug.transform.piecewiseaffine import PiecewiseAffineTransform\n",
      "from pybug.transform.affine import SimilarityTransform\n",
      "from scipy.spatial import Delaunay\n",
      "\n",
      "def pwa_constructor(src_landmarks, tgt_landmarks):\n",
      "    tri = Delaunay(src_landmarks)\n",
      "    return PiecewiseAffineTransform(src_landmarks, tgt_landmarks, tri.simplices)\n",
      "\n",
      "dummy_similarity_transform = SimilarityTransform.from_vector(np.array([0, 0, 0, 0]))\n",
      "global_transform = dummy_similarity_transform\n",
      "\n",
      "source = reference_frame.landmarks['PTS'].all_landmarks\n",
      "dummy_statistically_driven_transform = StatisticallyDrivenTransform(shape_model, pwa_constructor,\n",
      "                                                                    source=source, global_transform=global_transform,\n",
      "                                                                    composition='both')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Because we will not be using the Appearance Model yet, we need to build the appropiate template."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pybug.warp import scipy_warp\n",
      "\n",
      "trilist = reference_frame.get_landmark_set('ibug_68_trimesh').landmark_dict['tri'].trilist\n",
      "\n",
      "template_pwa = PiecewiseAffineTransform(source.points, test_shape.points, trilist)\n",
      "template = scipy_warp(test_image, reference_frame, template_pwa)\n",
      "\n",
      "template.view()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Build the \"fitter\" objects."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pybug.align.lucaskanade.residual import LSIntensity\n",
      "from pybug.align.lucaskanade.base import ImageForwardAdditive, ImageForwardCompositional, ImageInverseCompositional\n",
      "\n",
      "residual = LSIntensity()\n",
      "ifa = ImageForwardAdditive(template, residual, dummy_statistically_driven_transform)\n",
      "ifc = ImageForwardCompositional(template, residual, dummy_statistically_driven_transform)\n",
      "iic = ImageInverseCompositional(template, residual, dummy_statistically_driven_transform)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Initialize by scaling and translating the shape model mean using the scale and translation parameters from the ground truth shape."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pybug.transform.affine import SimilarityTransform\n",
      "import numpy as np\n",
      "\n",
      "# estimate similarity transform\n",
      "similarity_transform = SimilarityTransform.estimate(shape_model.mean.points, test_shape.points)\n",
      "global_parameters = similarity_transform.as_vector()\n",
      "# kill rotation\n",
      "global_parameters[1] = 0\n",
      "# add random gaussian noise to the ground truth parameters\n",
      "global_parameters += 0.1 * np.random.randn(4) \n",
      "\n",
      "global_transform = SimilarityTransform.from_vector(global_parameters)\n",
      "\n",
      "aligned_test_points = global_transform.inverse.apply(test_shape.points)\n",
      "aligned_test_shape = PointCloud(aligned_test_points)\n",
      "weights = shape_model.project(aligned_test_shape)\n",
      "\n",
      "initial_parameters = np.concatenate([global_parameters, np.zeros_like(weights)])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Check the correctness of the initialization."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "initial_transform = dummy_statistically_driven_transform.from_vector(initial_parameters)\n",
      "initial_warped_image = scipy_warp(test_image, template, initial_transform)\n",
      "\n",
      "test_image.add_landmark_set(\"initial\", {\"initial\": initial_transform.target})\n",
      "test_image.get_landmark_set(\"initial\").view()\n",
      "initial_warped_image.view()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Fit using the 3 curent methods for image alignment."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "optimal_transform_1 = ifa.align(test_image, initial_parameters)\n",
      "optimal_transform_2 = ifc.align(test_image, initial_parameters)\n",
      "optimal_transform_3 = iic.align(test_image, initial_parameters)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Visualize the results."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fitted_appearance_1 = scipy_warp(test_image, template, optimal_transform_1)\n",
      "fitted_appearance_2 = scipy_warp(test_image, template, optimal_transform_2)\n",
      "fitted_appearance_3 = scipy_warp(test_image, template, optimal_transform_3)\n",
      "\n",
      "fitted_appearance_1.view()\n",
      "fitted_appearance_2.view()\n",
      "fitted_appearance_3.view()\n",
      "\n",
      "test_image.add_landmark_set(\"fitting_results\", {\"ifa\": optimal_transform_1.target,\n",
      "                                                \"ifc\": optimal_transform_2.target,\n",
      "                                                \"iic\": optimal_transform_3.target})\n",
      "test_image.get_landmark_set(\"fitting_results\").with_label(\"ifa\").view()\n",
      "test_image.get_landmark_set(\"fitting_results\").with_label(\"ifc\").view()\n",
      "test_image.get_landmark_set(\"fitting_results\").with_label(\"iic\").view()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}