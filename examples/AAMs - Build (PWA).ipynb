{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Build Active Appearance Models (AAMs) with Piece-Wise Affine (PWA) warps\n",
      "##### Version 0.1"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 1 Load data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "-"
      }
     },
     "source": [
      "Use the **autoimporter** to automatically load the *annotated* training imagesof the *Labelled Faces Parts in the Wild (LFPW)* dataset."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pybug.io import auto_import\n",
      "from pybug.landmark.labels import ibug_68_points, ibug_68_contour, ibug_68_trimesh, labeller\n",
      "\n",
      "# load training images as landmarked images using the autoimporter\n",
      "images = auto_import('/vol/atlas/databases/lfpw/train (copy)/' + '*.png')\n",
      "\n",
      "# label landmarks using the ibug's \"standard\" 68 points mark-up\n",
      "labeller(images, 'PTS', ibug_68_points)\n",
      "labeller(images, 'PTS', ibug_68_contour)\n",
      "labeller(images, 'PTS', ibug_68_trimesh)"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "-"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "img = images[0]\n",
      "\n",
      "# visualize first image\n",
      "img.view()\n",
      "img.get_landmark_set('ibug_68_points').view()\n",
      "img.get_landmark_set('ibug_68_contour').view()\n",
      "img.get_landmark_set('ibug_68_trimesh').view()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We have now loaded enough data to create a meaninful **Active Appearance Model (AAM)** from the LFPW database."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 2. Build Template\n",
      "\n",
      "We start by centereing all shapes around the origin (0,0)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pybug.shape import PointCloud\n",
      "\n",
      "points = [img.landmarks['PTS'].all_landmarks.points - 1  for img in images]\n",
      "shapes = [PointCloud(p) for p in points]\n",
      "\n",
      "centralized_points = [p - np.mean(p, axis=0) for p in points]\n",
      "centralized_shapes = [PointCloud(p) for p in points]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can visualy check that indeed they are now centered."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "centralized_shapes[0].view()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Normalize the centered shapes up to a similarity transform by performing Procrustes Analysis."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pybug.align import GeneralizedProcrustesAnalysis\n",
      "\n",
      "gpa = GeneralizedProcrustesAnalysis(centralized_points)\n",
      "aligned_points = [p[-1].aligned_source for p in gpa.procrustes]\n",
      "aligned_shapes = [PointCloud(p) for p in aligned_points]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Define the template."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pybug.image.base import Image\n",
      "\n",
      "mean_points = np.mean(aligned_points, axis=0)\n",
      "margin = 3\n",
      "template_landmarks = PointCloud(mean_points - np.min(mean_points, axis=0) + margin)\n",
      "\n",
      "# the resolution of the template is typically related to the size of the mean shape\n",
      "scale = 1\n",
      "template_resolution = scale * np.ceil(np.max(template_landmarks.points, axis=0) + margin)\n",
      "\n",
      "template_data = np.zeros(template_resolution)\n",
      "\n",
      "# this looks a bit overcomplicated for what I end up doing... \n",
      "template_landmarks.add_landmark_set('PTS', {'all': template_landmarks})\n",
      "labeller([template_landmarks], 'PTS', ibug_68_contour)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pybug.image.base import MaskImage\n",
      "from skimage.morphology._pnpoly import points_inside_poly\n",
      "\n",
      "# same here...\n",
      "convex_hull = template_landmarks.get_landmark_set('ibug_68_contour').all_landmarks.points\n",
      "plot(convex_hull[:,0],convex_hull[:,1])\n",
      "\n",
      "y = np.arange(template_resolution[1], dtype=np.int)\n",
      "x = np.arange(template_resolution[0],  dtype=np.int)\n",
      "yv, xv = np.meshgrid(y, x)\n",
      "\n",
      "mask_data = np.zeros(template_resolution, dtype=np.bool)\n",
      "\n",
      "positions = np.array([xv.flatten(), yv.flatten()]).T\n",
      "mask_data = points_inside_poly(positions, convex_hull)\n",
      "mask_data = mask_data.reshape(template_resolution)\n",
      "\n",
      "mask = MaskImage(mask_data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pybug.image.base import Image\n",
      "\n",
      "template = Image(template_data, mask=mask)\n",
      "\n",
      "template.add_landmark_set('PTS', {'all': template_landmarks})\n",
      "labeller([template], 'PTS', ibug_68_points)\n",
      "labeller([template], 'PTS', ibug_68_contour)\n",
      "labeller([template], 'PTS', ibug_68_trimesh)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "template.get_landmark_set('ibug_68_points').view()\n",
      "template.get_landmark_set('ibug_68_contour').view()\n",
      "template.get_landmark_set('ibug_68_trimesh').view()\n",
      "\n",
      "template.mask.view()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def build_template(points, label_func=ibug_68_contour, margin=3, scale=1):\n",
      "    template_landmarks = PointCloud(points - np.min(points, axis=0) + margin)\n",
      "    template_resolution = scale * np.ceil(np.max(template_landmarks.points, axis=0) + margin)\n",
      "    template_data = np.zeros(template_resolution)\n",
      "    y = np.arange(template_resolution[1], dtype=np.int)\n",
      "    x = np.arange(template_resolution[0], dtype=np.int)\n",
      "    yv, xv = np.meshgrid(y, x)\n",
      "    mask_data = np.zeros(template_resolution, dtype=np.bool)\n",
      "    template_landmarks.add_landmark_set('PTS', {'all': template_landmarks})\n",
      "    labeller([template_landmarks], 'PTS', label_func)\n",
      "    convex_hull = template_landmarks.get_landmark_set('ibug_68_contour').all_landmarks.points\n",
      "    plot(convex_hull[:,0],convex_hull[:,1])\n",
      "    positions = np.array([xv.flatten(), yv.flatten()]).T\n",
      "    mask_data = points_inside_poly(positions, convex_hull)\n",
      "    mask_data = mask_data.reshape(template_resolution)\n",
      "    mask = MaskImage(mask_data)\n",
      "    template = Image(template_data, mask=mask)\n",
      "    return template, template_landmarks"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 3. Warp the Images\n",
      "\n",
      "The next step consists of *warping* the original LFPW images onto the *reference frame* using the correspondances between their *landmarks* and the *texture coordinates* on the reference frame. We can either use **Piece Wise Affine ** (PWA) or **Thin Plate Spline ** (TPS) for this purpose. The differences between the two families of warps can be observed by visualizing the obtained warped images."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pybug.transform.piecewiseaffine import PiecewiseAffineTransform\n",
      "from pybug.warp import scipy_warp\n",
      "\n",
      "trilist = template.get_landmark_set('ibug_68_trimesh').landmark_dict['tri'].trilist\n",
      "\n",
      "pwa = [PiecewiseAffineTransform(template_landmarks.points, s.points, trilist) for s in shapes]\n",
      "warped_images = [scipy_warp(img, template, t) for img, t in zip(images, pwa)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "warped_images[0].view()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 4. Build the Appearance Model\n",
      "The AAM's *appearance model* is typically build by applying **Principal Component Analysis** (PCA) to the previously warped images."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pybug.model.linear import PCAModel\n",
      "\n",
      "# transform all warped images to graysacale\n",
      "grayscale_warped_images = [img.as_greyscale() for img in warped_images] \n",
      "\n",
      "# this would perfectly work in rgb space provided that all original images had rgb color channels (which is not the \n",
      "# case for the LFPW training dataset)\n",
      "appearance_model = PCAModel(grayscale_warped_images, n_components=50)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n_instances = 10\n",
      "appearance_parameters = [np.random.randn(appearance_model.n_components) for i in range(n_instances)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x_axis = range(appearance_model.n_components)\n",
      "cumulative_variance = [np.sum(appearance_model.explained_variance_ratio[:i]) for i in x_axis]\n",
      "\n",
      "appearance_instances = [appearance_model.instance(appearance_parameters[i] * \n",
      "                        np.sqrt(appearance_model.explained_variance)) for i in range(n_instances)]\n",
      "\n",
      "subplot(1,2,1)\n",
      "plot(x_axis, cumulative_variance)\n",
      "subplot(1,2,2)\n",
      "appearance_instances[0].view()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 5. Build the Shape Model\n",
      "Similarly, the shape model of the AAM is tipically build by applying PCA to the aligned shapes obtained from GPA. At this point, it is interesting to see the differences between the sets of original, centralized and aligned shapes."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#for s in shapes:\n",
      "#    s.view()\n",
      "#for p in centralized_points:\n",
      "#    PointCloud(p).view()\n",
      "#for s in aligned_shapes:\n",
      "#    s.view()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pybug.model.linear import PCAModel\n",
      "\n",
      "shape_model_1 = PCAModel(aligned_shapes, n_components=3)\n",
      "shape_model_2 = PCAModel(aligned_shapes, n_components=6)\n",
      "shape_model_3 = PCAModel(aligned_shapes, n_components=12)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n_instances = 10\n",
      "shape_parameters = [np.random.randn(shape_model.n_components) for i in range(n_instances)]\n",
      "\n",
      "x_axis = range(shape_model.n_components)\n",
      "cumulative_variance = [np.sum(shape_model.explained_variance_ratio[:i]) for i in x_axis]\n",
      "\n",
      "shape_instances = [shape_model.instance(shape_parameters[i] * np.sqrt(shape_model.explained_variance)) \n",
      "    for i in range(n_instances)]\n",
      "\n",
      "subplot(1,2,1)\n",
      "plot(x_axis, cumulative_variance)\n",
      "subplot(1,2,2)\n",
      "shape_instances[0].view()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 6. Generate an AAM instance"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "i = np.random.randint(n_instances)\n",
      "\n",
      "shape_instance = shape_instances[i]\n",
      "\n",
      "# build a template for the chosen shape instance\n",
      "instance_template, instance_landmarks = build_template(shape_instance.points)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "instance = PiecewiseAffineTransform(instance_landmarks.points, template_landmarks.points, trilist)\n",
      "model_instance = scipy_warp(appearance_instances[i], instance_template, instance)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model_instance.view()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 7. Save the AAM"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pickle\n",
      "\n",
      "pickle.dump({'shape_model_1': shape_model_1,\n",
      "             'shape_model_2': shape_model_2,\n",
      "             'shape_model_3': shape_model_3,\n",
      "             'appearance_model': appearance_model,\n",
      "             'template': template}, open( \"/vol/atlas/aams/lfpw_pwa\", \"wb\" ))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}