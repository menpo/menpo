{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Cython: Optimising for speed\n",
      "============================\n",
      "This notebook aims to take the reader through a realworld example of increasing the speed on an algorithm. The given example is that of computing the normals for a given triangle mesh (points and a trilist). Computing the per-vertex normal for a mesh is an intensive operation that yields poor performance in pure Python. This is due to the need to loop over every triangle and and sum the per-triangle normal that every vertex is a member of. This notebook is not designed to describe Cython syntax or basics. It is assumed that the reader has some understanding and preferably experience with writing Cythonised functions.\n",
      "\n",
      "Algorithm Pseudocode\n",
      "--------------------\n",
      "\n",
      "```\n",
      "foreach face in faces:\n",
      "    face_normal = crossproduct(vertices[face[1]] - vertices[face[0]], \n",
      "                               vertices[face[2]] - vertices[face[0]])\n",
      "    foreach v in face:\n",
      "        normalise(face_normal)\n",
      "        vertices[v].in_faces.append(face_normal)\n",
      "\n",
      "foreach vertex in vertices:\n",
      "    normal = (0,0,0)\n",
      "    for face in vertex.in_faces:\n",
      "        normal += face_normal\n",
      "    normalise(normal)\n",
      "\n",
      "crossproduct(v0, v1):\n",
      "        v0.y * v1.z - v0.z * v1.y,\n",
      "        v0.z * v1.x - v0.x * v1.z,\n",
      "        v0.x * v1.y - v0.y * v1.x,\n",
      "```\n",
      "\n",
      "Begin\n",
      "-----\n",
      "We begin by loading an appropriate mesh."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pybug.io import auto_import\n",
      "import numpy as np\n",
      "\n",
      "shapeimage = auto_import('/vol/atlas/databases/frgc/spring2003/04201d302.abs')[0]\n",
      "tris = shapeimage.mesh.trilist\n",
      "points = shapeimage.mesh.points\n",
      "\n",
      "print shapeimage"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Pure Python Implementation\n",
      "--------------------------\n",
      "This implementation uses numpy and broadcasting to achieve it's goals."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def normalise(vec):\n",
      "    # Avoid divisions by almost 0 numbers\n",
      "    # np.spacing(1) is equivalent to Matlab's eps\n",
      "    d = np.sqrt(np.sum(vec ** 2, axis=1))\n",
      "    d[d < np.spacing(1)] = 1.0\n",
      "    return vec / d[..., None]\n",
      "\n",
      "def py_compute_normal(vertex, face):\n",
      "    nface = face.shape[0]\n",
      "    nvert = vertex.shape[0]\n",
      "    \n",
      "    # Calculate the cross product (per-face normal)\n",
      "    normalf = np.cross(vertex[face[:, 1], :] - vertex[face[:, 0], :],\n",
      "                       vertex[face[:, 2], :] - vertex[face[:, 0], :])\n",
      "    normalf = normalise(normalf)\n",
      "    \n",
      "    # Calculate per-vertex normal\n",
      "    normal = np.zeros([nvert, 3])\n",
      "    for i in xrange(nface):\n",
      "        f = face[i, :]\n",
      "        for j in xrange(3):\n",
      "            normal[f[j], :] += normalf[i, :]\n",
      "            \n",
      "    # Normalize\n",
      "    normal = normalise(normal)\n",
      "    \n",
      "    # Enforce that the normal are outward\n",
      "    v = vertex - np.mean(vertex)[..., None]\n",
      "    s = np.sum(v * normal, axis=1)\n",
      "    if np.sum(np.greater(s, 0)) < np.sum(np.less(s, 0)):\n",
      "        # flip\n",
      "        normal = -normal\n",
      "        normalf = -normalf\n",
      "    \n",
      "    return normal, normalf"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If we then time this function, we can see that it takes about 3 seconds (on my ``Intel(R) Xeon(R) CPU E5-1650 @ 3.20GHz`` with ``32GB`` of RAM) for ``123160`` triangles and ``61599`` points."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit py_compute_normal(points, tris)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Naive Cython\n",
      "------------\n",
      "This is obviously far too slow to be of any use. Therefore, we naively port this method to Cython. Cython is useful for code where tight looping is unavoidable, as is the case in computing the per-vertex normal. This is because it pre-compiles as much of the code as possible down to C, which is very efficient at tight looping. To compile Cython code, we have to load the Cython magic extension"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext cythonmagic"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The Cython extension gives us the ``%%cython`` cell magic where we can put raw Cython code which will compiled on execution. TO get started with Cython, we note that the majority of Cython's speedup comes from the fact that we statically type variables.  Therefore, we always have to import some C code via the ``cimport`` statement. For example, to use numpy, we could use:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%cython\n",
      "import numpy as np\n",
      "\n",
      "cimport cython\n",
      "cimport numpy as np"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Note that we have to Python ``import`` Numpy **AND** ``cimport`` it. Therefore, a simple Cython function using numpy would look like:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%cython\n",
      "import numpy as np\n",
      "\n",
      "cimport cython\n",
      "cimport numpy as np\n",
      "\n",
      "def my_pow(double x):\n",
      "    return np.power(x, 2)\n",
      "\n",
      "print my_pow(2.0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It's important to note that there are 3 kinds of functions definitions in Cython:\n",
      "\n",
      "  - ``def``\n",
      "    - This is a Python function. It is called via Python and thus has all the overhead of being called by Python. Any C-code will have to call out of Python\n",
      "    - Parameters are Python objects which are then explicitly converted to static types if specified\n",
      "    - Returns a Python object\n",
      "  - ``cdef``\n",
      "    - This is a C signature and can **ONLY** run from a Cython context. It cannot be called by pure Python code.\n",
      "    - Parameters are converted to static type by the caller\n",
      "    - Return type can be statitically defined\n",
      "  - ``cpdef``\n",
      "    - This is a mixed signature whereby Cython automatically builds a pure Python wrapper around a ``cdef`` function. So Python calls the wrapper and C calls the ``cdef`` function.\n",
      "    - Parameters are converted to C type of Python wrapper\n",
      "    - Return types are statically defined and marshalled by Python wrapper\n",
      "    \n",
      "So, to create a naive implementation of our Python function, in Cython, we define  ``cpdef`` function as follows:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%cython\n",
      "\n",
      "import numpy as np\n",
      "cimport numpy as np\n",
      "cimport cython\n",
      "\n",
      "\n",
      "cdef np.ndarray[np.float64_t, ndim=2] cy_normalise_naive(np.ndarray[np.float64_t, ndim=2] vec):\n",
      "    # Avoid divisions by almost 0 numbers\n",
      "    cdef np.ndarray[np.float64_t, ndim=1] d = np.sqrt(np.sum(vec ** 2, axis=1))\n",
      "    d[d < np.spacing(1)] = 1.0\n",
      "    return vec / d[..., None]\n",
      " \n",
      "\n",
      "cpdef cy_compute_normal_naive(np.ndarray[np.float64_t, ndim=2] vertex, np.ndarray[int, ndim=2] face):\n",
      "    cdef int nface = face.shape[0]\n",
      "    cdef int nvert = vertex.shape[0]\n",
      "    \n",
      "    # Calculate the cross product (per-face normal)\n",
      "    cdef np.ndarray[np.float64_t, ndim=2] normalf = np.cross(vertex[face[:, 1], :] - vertex[face[:, 0], :],\n",
      "                                                             vertex[face[:, 2], :] - vertex[face[:, 0], :])\n",
      "    normalf = cy_normalise_naive(normalf)\n",
      "    \n",
      "    # Calculate per-vertex normal\n",
      "    cdef np.ndarray[np.float64_t, ndim=2] normal = np.zeros([nvert, 3])\n",
      "    cdef np.ndarray[int, ndim=1] f\n",
      "    for i in xrange(nface):\n",
      "        f = face[i, :]\n",
      "        for j in xrange(3):\n",
      "            normal[f[j], :] += normalf[i, :]\n",
      "    \n",
      "    # Normalize\n",
      "    normal = cy_normalise_naive(normal)\n",
      "    \n",
      "    # Enforce that the normal are outward\n",
      "    cdef np.ndarray[np.float64_t, ndim=2] v = vertex - np.mean(vertex)[..., None]\n",
      "    cdef np.ndarray[np.float64_t, ndim=1] s = np.sum(v * normal, axis=1)\n",
      "    if np.sum(np.greater(s, 0)) < np.sum(np.less(s, 0)):\n",
      "        # flip\n",
      "        normal = -normal\n",
      "        normalf = -normalf\n",
      "    \n",
      "    return normal, normalf"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If we then time this function, we can see that it takes about 1.8 seconds (on my ``Intel(R) Xeon(R) CPU E5-1650 @ 3.20GHz`` with ``32GB`` of RAM) for ``123160`` triangles and ``61599`` points. This represents an approximately 1.6x speedup just by naively moving the code in to a Cython function. Other than the static typing, the code is almost identical.\n",
      "\n",
      "*Note:* There are decorators such as ``@cython.boundscheck(False)`` and ``@cython.wraparound(False)`` that can provide speedups by telling Cython that you guarantee the kinds of accesses arrays will have inside the function. See [here](http://docs.cython.org/src/reference/compilation.html) for more information."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit cy_compute_normal_naive(points, tris)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Optimising Cython\n",
      "-----------------\n",
      "However, we can do better than this! In order to give us a better indiciaton, Cython provides the ability to pass flags in for execution. These can be compile time flags, or special running flags. The flag we are interested in is ``-a``. This provides an output that colour codes the typing that is going on within the Cython function. Yellow backgrounds indicate function calls back in to Python (which is slow), and white/clear backgrounds represent pure C calls. If we run this on our naive implementaton, we get the following:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%cython -a\n",
      "\n",
      "import numpy as np\n",
      "cimport numpy as np\n",
      "cimport cython\n",
      "\n",
      "\n",
      "cdef np.ndarray[np.float64_t, ndim=2] cy_normalise_naive(np.ndarray[np.float64_t, ndim=2] vec):\n",
      "    # Avoid divisions by almost 0 numbers\n",
      "    cdef np.ndarray[np.float64_t, ndim=1] d = np.sqrt(np.sum(vec ** 2, axis=1))\n",
      "    d[d < np.spacing(1)] = 1.0\n",
      "    return vec / d[..., None]\n",
      " \n",
      "\n",
      "cpdef cy_compute_normal_naive(np.ndarray[np.float64_t, ndim=2] vertex, np.ndarray[int, ndim=2] face):\n",
      "    cdef int nface = face.shape[0]\n",
      "    cdef int nvert = vertex.shape[0]\n",
      "    \n",
      "    # unit normals to the faces\n",
      "    cdef np.ndarray[np.float64_t, ndim=2] normalf = np.cross(vertex[face[:, 1], :] - vertex[face[:, 0], :],\n",
      "                                                             vertex[face[:, 2], :] - vertex[face[:, 0], :])\n",
      "    normalf = cy_normalise_naive(normalf)\n",
      "    \n",
      "    # unit normal to the vertex\n",
      "    cdef np.ndarray[np.float64_t, ndim=2] normal = np.zeros([nvert, 3])\n",
      "    cdef double[:] f\n",
      "    for i in xrange(nface):\n",
      "        f = face[i, :]\n",
      "        for j in xrange(3):\n",
      "            normal[f[j], :] += normalf[i, :]\n",
      "    \n",
      "    # normalize\n",
      "    normal = cy_normalise_naive(normal)\n",
      "    \n",
      "    # enforce that the normal are outward\n",
      "    cdef np.ndarray[np.float64_t, ndim=2] v = vertex - np.mean(vertex)[..., None]\n",
      "    cdef np.ndarray[np.float64_t, ndim=1] s = np.sum(v * normal, axis=1)\n",
      "    if np.sum(np.greater(s, 0)) < np.sum(np.less(s, 0)):\n",
      "        # flip\n",
      "        normal = -normal\n",
      "        normalf = -normalf\n",
      "    \n",
      "    return normal, normalf"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Looking above, we see that the majority of the code is still making calls back in to Python. In particular, the slow vetex loop is making a Python call **every iteration**. Therefore, we want to try and remove this."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%cython -a\n",
      "\n",
      "import numpy as np\n",
      "cimport numpy as np\n",
      "cimport cython\n",
      "\n",
      "\n",
      "cdef np.ndarray[np.float64_t, ndim=2] cy_normalise_naive(np.ndarray[np.float64_t, ndim=2] vec):\n",
      "    # Avoid divisions by almost 0 numbers\n",
      "    cdef np.ndarray[np.float64_t, ndim=1] d = np.sqrt(np.sum(vec ** 2, axis=1))\n",
      "    d[d < np.spacing(1)] = 1.0\n",
      "    return vec / d[..., None]\n",
      " \n",
      "    \n",
      "cpdef cy_compute_normal_better(np.ndarray[np.float64_t, ndim=2] vertex, np.ndarray[int, ndim=2] face):\n",
      "    cdef int nface = face.shape[0]\n",
      "    cdef int nvert = vertex.shape[0]\n",
      "    \n",
      "    # unit normals to the faces\n",
      "    cdef np.ndarray[np.float64_t, ndim=2] normalf = np.cross(vertex[face[:, 1], :] - vertex[face[:, 0], :],\n",
      "                                                             vertex[face[:, 2], :] - vertex[face[:, 0], :])\n",
      "    normalf = cy_normalise_naive(normalf)\n",
      "    \n",
      "    # unit normal to the vertex\n",
      "    cdef np.ndarray[np.float64_t, ndim=2] normal = np.zeros([nvert, 3])\n",
      "    cdef int f0, f1, f2\n",
      "    for i in range(nface):\n",
      "        f0 = face[i, 0]\n",
      "        f1 = face[i, 1]\n",
      "        f2 = face[i, 2]\n",
      "        for j in range(3):\n",
      "            normal[f0, j] += normalf[i, j]   \n",
      "            normal[f1, j] += normalf[i, j]       \n",
      "            normal[f2, j] += normalf[i, j]\n",
      "    \n",
      "    # normalize\n",
      "    normal = cy_normalise_naive(normal)\n",
      "    \n",
      "    # enforce that the normal are outward\n",
      "    cdef np.ndarray[np.float64_t, ndim=2] v = vertex - np.mean(vertex)[..., None]\n",
      "    cdef np.ndarray[np.float64_t, ndim=1] s = np.sum(v * normal, axis=1)\n",
      "    if np.sum(np.greater(s, 0)) < np.sum(np.less(s, 0)):\n",
      "        # flip\n",
      "        normal = -normal\n",
      "        normalf = -normalf\n",
      "    \n",
      "    return normal, normalf"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Eureka! By turning lines ``24-36`` to pure C, just by guaranteeing their accesses as C types, we have sped up our function to approximately 80 ms. This represents an approximate 38x speedup from the original! And all we did was partially unwrap a single loop. This is the key when trying to optimise Cython code. You need to ensure that all loops make as few calls in to Python code as possible."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit cy_compute_normal_better(points, tris)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Diminishing Returns\n",
      "-------------------\n",
      "So now the game has become trying to turn as much of that Yellow code in to white code. Note that there is certainly a diminishing law of returns going on here. Our previous optimisation was almost certainly the largest jump in performance we will be able to achieve. Given that we don't gave any other loops, we are unlikely to get large 100+% jumps in performance. Numpy calls are already vectorized and manually unrolling them in to loops will not yield a very big performance boost. If we run the magic function ``%prun``, this will give us profiling information about the functions that are called. We use the ``-r`` flag in order to return the profiler object so that we can print it in to the cell. Normally, this need just be called as:\n",
      "\n",
      "```python\n",
      "    %prun cy_compute_normal_better(points, tris)\n",
      "```\n",
      "\n",
      "which opens up a seperate window in the notebook."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "p = %prun -r cy_compute_normal_better(points, tris)\n",
      "p.print_stats()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The profiling output tells us that the majority of the time is spent inside the Cython function. However, almost half the time is spent inside the numpy cross product function. Looking at the source code of numpy's cross product shows us that it does a bunch of checks to try and ensure that the shapes of the vectors match. However, we know that are guaranteed to have standard ``Nx3`` vectors. So, what happens if we roll our own cross product method?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%cython -a\n",
      "\n",
      "import numpy as np\n",
      "cimport numpy as np\n",
      "cimport cython\n",
      "\n",
      "        \n",
      "cdef np.ndarray[np.float64_t, ndim=2] normalise(np.ndarray[np.float64_t, ndim=2] vec):\n",
      "    # Avoid divisions by almost 0 numbers\n",
      "    cdef np.ndarray[np.float64_t, ndim=1] d = np.sqrt(np.sum(vec ** 2, axis=1))\n",
      "    d[d < np.spacing(1)] = 1.0\n",
      "    return vec / d[..., None]\n",
      "     \n",
      "\n",
      "cdef inline np.ndarray[np.float64_t, ndim=2] cross(double[:, :] x, double[:, :] y):\n",
      "    cdef np.ndarray[np.float64_t, ndim=2] z = np.empty_like(x)\n",
      "    cdef int n = x.shape[0]\n",
      "    for i in range(n):\n",
      "        z[i, 0] = x[i, 1] * y[i, 2] - x[i, 2] * y[i, 1]\n",
      "        z[i, 1] = x[i, 2] * y[i, 0] - x[i, 0] * y[i, 2]\n",
      "        z[i, 2] = x[i, 0] * y[i, 1] - x[i, 1] * y[i, 0]\n",
      "    \n",
      "    return z\n",
      "\n",
      "\n",
      "cpdef cy_compute_normal(np.ndarray[np.float64_t, ndim=2] vertex, np.ndarray[int, ndim=2] face):\n",
      "    cdef int nface = face.shape[0]\n",
      "    cdef int nvert = vertex.shape[0]\n",
      "    \n",
      "    # unit normals to the faces\n",
      "    cdef np.ndarray[np.float64_t, ndim=2] normalf = cross(vertex[face[:, 1], :] - vertex[face[:, 0], :],\n",
      "                                                          vertex[face[:, 2], :] - vertex[face[:, 0], :])\n",
      "    normalf = normalise(normalf)\n",
      "    \n",
      "    # unit normal to the vertex\n",
      "    cdef np.ndarray[np.float64_t, ndim=2] normal = np.zeros([nvert, 3])\n",
      "    cdef int f0, f1, f2\n",
      "    for i in range(nface):\n",
      "        f0 = face[i, 0]\n",
      "        f1 = face[i, 1]\n",
      "        f2 = face[i, 2]\n",
      "        for j in range(3):\n",
      "            normal[f0, j] += normalf[i, j]   \n",
      "            normal[f1, j] += normalf[i, j]       \n",
      "            normal[f2, j] += normalf[i, j]\n",
      "    \n",
      "    # normalize\n",
      "    normal = normalise(normal)\n",
      "    \n",
      "    # enforce that the normal are outward\n",
      "    cdef np.ndarray[np.float64_t, ndim=2] v = vertex - np.mean(vertex)[..., None]\n",
      "    cdef np.ndarray[np.float64_t, ndim=1] s = np.sum(v * normal, axis=1)\n",
      "    if np.sum(np.greater(s, 0)) < np.sum(np.less(s, 0)):\n",
      "        # flip\n",
      "        normal = -normal\n",
      "        normalf = -normalf\n",
      "    \n",
      "    return normal, normalf"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit cy_compute_normal(points, tris)\n",
      "print \"\"\n",
      "p = %prun -r cy_compute_normal(points, tris)\n",
      "p.print_stats()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Basic Results\n",
      "-------------\n",
      "We've now reduced the execution time by almost a third again. Looking at the profiler output, we see that all of the time is simply spent inside the Cython function. Since all the operations are vectorized, we are unlikely to see anything but very incremental improvements. However, we've gone from nearly 3s down to around 50ms. Looking at the code, we've changed very little from the original Python version. Easily the most difficult part was rolling our own cross product, and even that was not really a necessary optimisation.\n",
      "\n",
      "Now, just for our own piece of mind, we'll check that our optimised Cython version produces the same output as the original Python implementation."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cy_normal, cy_normalf = cy_compute_normal(points, tris)\n",
      "py_normal, py_normalf = py_compute_normal(points, tris)\n",
      "\n",
      "print np.allclose(cy_normal, py_normal)\n",
      "print np.allclose(cy_normalf, py_normalf)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Numba\n",
      "-----\n",
      "By request I have implemented the algorithm as best I could in Numba. I should note that:\n",
      "\n",
      "  - I have no idea what I'm doing using Numba, so this is unlikely to be optimised\n",
      "  - I had enormous trouble even getting Numba to run on Ubuntu 13.04. I had to build and install my own LLVM-3.2.\n",
      "  - It took my about 2 hours just to get something to compile, and I had to resort to ``print`` statements because the output is so useless\n",
      "  \n",
      "I've tried to comment why I did certain unrollings, though I don't justify them because I don't really understand them. I assume that specifying the expected type will help the optimisation - but I honestly have no idea. Presumably the ``np.greater`` and ``np.less`` problem is a bug in Numba?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numba\n",
      "from numba.decorators import autojit, jit\n",
      "from math import sqrt\n",
      "\n",
      "\n",
      "# Had to unroll this otherwise it complained about some strange python object\n",
      "# coercion error\n",
      "@autojit\n",
      "def numba_normalise(vec):\n",
      "    # Avoid divisions by almost 0 numbers\n",
      "    # np.spacing(1) is equivalent to Matlab's eps\n",
      "    n = vec.shape[0]\n",
      "    for i in range(n):\n",
      "        d = sqrt(vec[i, 0] * vec[i, 0] +\n",
      "                 vec[i, 1] * vec[i, 1] +\n",
      "                 vec[i, 2] * vec[i, 2])\n",
      "        if d < np.spacing(1):\n",
      "            d = 1.0\n",
      "\n",
      "        vec[i, 0] /= d\n",
      "        vec[i, 1] /= d\n",
      "        vec[i, 2] /= d\n",
      "\n",
      "\n",
      "# If I didn't roll my own cross product then computing\n",
      "# the normals actually takes LONGER than the pure Python implementation\n",
      "@jit(argtypes=(numba.double[:, :], numba.double[:, :]))\n",
      "def cross_numba(x, y):\n",
      "    output = np.empty_like(x)\n",
      "    n = x.shape[0]\n",
      "    for i in range(n):\n",
      "        output[i, 0] = x[i, 1] * y[i, 2] - x[i, 2] * y[i, 1]\n",
      "        output[i, 1] = x[i, 2] * y[i, 0] - x[i, 0] * y[i, 2]\n",
      "        output[i, 2] = x[i, 0] * y[i, 1] - x[i, 1] * y[i, 0]\n",
      "    return output\n",
      "\n",
      "\n",
      "@jit(argtypes=(numba.double[:, :], numba.int32[:, :]))\n",
      "def numba_compute_normal(vertex, face):\n",
      "    nface = face.shape[0]\n",
      "\n",
      "    # Calculate the cross product (per-face normal)\n",
      "    normalf = cross_numba(vertex[face[:, 1], :] - vertex[face[:, 0], :],\n",
      "                          vertex[face[:, 2], :] - vertex[face[:, 0], :])\n",
      "    numba_normalise(normalf)\n",
      "\n",
      "    # Calculate per-vertex normal\n",
      "    normal = np.zeros_like(vertex)\n",
      "    for i in range(nface):\n",
      "        f = face[i, :]\n",
      "        for j in range(3):\n",
      "            normal[f[j], :] += normalf[i, :]\n",
      "\n",
      "    # Normalize\n",
      "    numba_normalise(normal)\n",
      "\n",
      "    # Enforce that the normal are outward\n",
      "    v = vertex - np.mean(vertex)[..., None]\n",
      "    s = np.sum(v * normal, axis=1)\n",
      "    s_gt_sum = 0\n",
      "    s_lt_sum = 0\n",
      "\n",
      "    # Had to expand this loop otherwise numba complained:\n",
      "    # 'only length-1 arrays can be converted to Python scalars'\n",
      "    # On the calls to np.greater and np.less\n",
      "    for i in range(s.shape[0]):\n",
      "        if s[i] > 0:\n",
      "            s_gt_sum += 1\n",
      "        elif s[i] < 0:\n",
      "            s_lt_sum += 1\n",
      "\n",
      "    if s_gt_sum < s_lt_sum:\n",
      "        # flip\n",
      "        normal = -normal\n",
      "        normalf = -normalf\n",
      "\n",
      "    return normal, normalf"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As for the results, we've gone down to around 800ms, which is definitely an improvement. Interestingly, this is on par with a Matlab implementation that I have (which is known to be jitted). To sanity check we will also check that the output is correct."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit numba_compute_normal(points, tris)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "numba_normal, numba_normalf = numba_compute_normal(points, tris)\n",
      "py_normal, py_normalf = py_compute_normal(points, tris)\n",
      "\n",
      "print np.allclose(numba_normal, py_normal)\n",
      "print np.allclose(numba_normalf, py_normalf)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}