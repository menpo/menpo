{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Fit AAMs using the Adaptive algorithm\n",
      "\n",
      "### 1. Load the data\n",
      "\n",
      "Use the **autoimporter** to automatically load the *annotated* test images of the *Labelled Faces Parts in the Wild (LFPW)* dataset:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pybug.io import auto_import\n",
      "from pybug.landmark.labels import  (labeller, ibug_68_points, \n",
      "                                    ibug_68_contour, ibug_68_trimesh)\n",
      "from pybug.shape import PointCloud\n",
      "\n",
      "# load the training images of the LFPW database as landmarked images using the autoimporter\n",
      "images = auto_import('/vol/atlas/databases/lfpw/test/' + '*.png')\n",
      "\n",
      "# label the landmarks using the ibug's \"standard\" 68 points mark-up\n",
      "labeller(images, 'PTS', ibug_68_points)\n",
      "labeller(images, 'PTS', ibug_68_contour)\n",
      "labeller(images, 'PTS', ibug_68_trimesh)\n",
      "\n",
      "# Extract shape data. -1 because the annotation are 1 based\n",
      "points = [img.landmarks['PTS'].all_landmarks.points - 1  for img in images]\n",
      "shapes = [PointCloud(p) for p in points]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Use **pickle** to load a previously build *AAM*:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pickle\n",
      "\n",
      "# load a previously buid AAM\n",
      "aam = pickle.load(open('/vol/atlas/aams/lfpw_pwa', \"rb\"))\n",
      "\n",
      "reference_frame = aam[\"template\"]\n",
      "appearance_model = aam[\"appearance_model\"]\n",
      "shape_model = aam[\"shape_model_1\"]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 2. Fit\n",
      "\n",
      "Randomly select an image to fit:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "\n",
      "# select a test image at random\n",
      "ind = np.random.randint(len(images))\n",
      "test_image = images[ind].as_greyscale()\n",
      "test_shape = shapes[ind]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Visualize ground truth landmarks and warped appearance for the selected test image:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pybug.transform.piecewiseaffine import PiecewiseAffineTransform\n",
      "from pybug.warp import scipy_warp\n",
      "\n",
      "source = reference_frame.landmarks['PTS'].all_landmarks\n",
      "trilist = reference_frame.get_landmark_set('ibug_68_trimesh').landmark_dict['tri'].trilist\n",
      "template_pwa = PiecewiseAffineTransform(source.points, test_shape.points, trilist)\n",
      "template = scipy_warp(test_image, reference_frame, template_pwa)\n",
      "\n",
      "test_image.add_landmark_set(\"ground_truth\", {\"ground_truth\": test_shape})\n",
      "test_image.get_landmark_set(\"ground_truth\").with_label('ground_truth').view()\n",
      "gcf().set_size_inches((10,10))\n",
      "\n",
      "template.add_landmark_set('reference', {'reference': source})\n",
      "template.get_landmark_set('reference').with_label('reference').view()\n",
      "gcf().set_size_inches((6,6))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Build Statistically Driven Transform using the AAM's shape model and Piece Wise Affine (PWA) warps: "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pybug.transform.statisticallydriven import StatisticallyDrivenTransform\n",
      "from pybug.transform.affine import SimilarityTransform\n",
      "from scipy.spatial import Delaunay\n",
      "\n",
      "def pwa_constructor(src_landmarks, tgt_landmarks):\n",
      "    tri = Delaunay(src_landmarks)\n",
      "    return PiecewiseAffineTransform(src_landmarks, tgt_landmarks, tri.simplices)\n",
      "\n",
      "dummy_similarity_transform = SimilarityTransform.from_vector(np.array([0, 0, 0, 0]))\n",
      "global_transform = dummy_similarity_transform\n",
      "\n",
      "stat_driven_transform = StatisticallyDrivenTransform(shape_model, pwa_constructor,\n",
      "                                                     source=source, \n",
      "                                                     global_transform=global_transform)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Build three \"fitter\" objects using the three variations of the Project Out algorithm:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pybug.align.lucaskanade.residual import LSIntensity\n",
      "from pybug.align.lucaskanade.appearance.adaptive import (AdaptiveForwardAdditive,\n",
      "                                                         AdaptiveForwardCompositional, \n",
      "                                                         AdaptiveInverseCompositional)\n",
      "\n",
      "# standard Least Squares Residual\n",
      "residual = LSIntensity()\n",
      "\n",
      "# forward additive\n",
      "fa = AdaptiveForwardAdditive(appearance_model, residual, stat_driven_transform)\n",
      "# forwad compositional\n",
      "fc = AdaptiveForwardCompositional(appearance_model, residual, stat_driven_transform)\n",
      "# inverse compositional\n",
      "ic = AdaptiveInverseCompositional(appearance_model, residual, stat_driven_transform)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Initialize the fitting procedure by perturbing the true scale and translation parameters of the manually annotated shape:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pybug.transform.affine import SimilarityTransform\n",
      "import numpy as np\n",
      "\n",
      "# estimate the true similarity transform\n",
      "similarity_transform = SimilarityTransform.estimate(shape_model.mean.points, \n",
      "                                                    test_shape.points)\n",
      "\n",
      "global_parameters = similarity_transform.as_vector()\n",
      "# kill rotation\n",
      "global_parameters[1] = 0\n",
      "# add random gaussian noise to the ground truth parameters\n",
      "global_parameters += 0.1 * np.random.randn(4) \n",
      "\n",
      "global_transform = SimilarityTransform.from_vector(global_parameters)\n",
      "\n",
      "aligned_test_points = global_transform.inverse.apply(test_shape.points)\n",
      "aligned_test_shape = PointCloud(aligned_test_points)\n",
      "weights = shape_model.project(aligned_test_shape)\n",
      "\n",
      "initial_parameters = np.concatenate([global_parameters, np.zeros_like(weights)])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Check the correctness of the initialization:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "initial_transform = stat_driven_transform.from_vector(initial_parameters)\n",
      "initial_warped_image = scipy_warp(test_image, template, initial_transform)\n",
      "\n",
      "test_image.add_landmark_set(\"initial\", {\"initial\": initial_transform.target})\n",
      "test_image.get_landmark_set(\"initial\").view()\n",
      "gcf().set_size_inches((10,10))\n",
      "\n",
      "initial_warped_image.add_landmark_set('reference', {'reference': source})\n",
      "initial_warped_image.get_landmark_set('reference').with_label('reference').view()\n",
      "gcf().set_size_inches((6,6))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Fit the image using all three different methods:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%time optimal_transform_1 = fa.align(test_image, initial_parameters, max_iters=50)\n",
      "%time optimal_transform_2 = fc.align(test_image, initial_parameters, max_iters=50)\n",
      "%time optimal_transform_3 = ic.align(test_image, initial_parameters, max_iters=50)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Visualize the results:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fitted_appearance_1 = scipy_warp(test_image, template, optimal_transform_1)\n",
      "fitted_appearance_2 = scipy_warp(test_image, template, optimal_transform_2)\n",
      "fitted_appearance_3 = scipy_warp(test_image, template, optimal_transform_3)\n",
      "\n",
      "fitted_appearance_1.add_landmark_set('reference', {'reference': source})\n",
      "fitted_appearance_1.get_landmark_set('reference').with_label('reference').view()\n",
      "gcf().set_size_inches((6,6))\n",
      "\n",
      "fitted_appearance_2.add_landmark_set('reference', {'reference': source})\n",
      "fitted_appearance_2.get_landmark_set('reference').with_label('reference').view()\n",
      "gcf().set_size_inches((6,6))\n",
      "\n",
      "fitted_appearance_3.add_landmark_set('reference', {'reference': source})\n",
      "fitted_appearance_3.get_landmark_set('reference').with_label('reference').view()\n",
      "gcf().set_size_inches((6,6))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_image.add_landmark_set('fitting_results', {'fa': optimal_transform_1.target,\n",
      "                                                'fc': optimal_transform_2.target,\n",
      "                                                'ic': optimal_transform_3.target})\n",
      "\n",
      "test_image.get_landmark_set('fitting_results').with_label('fa').view()\n",
      "gcf().set_size_inches((10,10))\n",
      "\n",
      "test_image.get_landmark_set('fitting_results').with_label('fc').view()\n",
      "gcf().set_size_inches((10,10))\n",
      "\n",
      "test_image.get_landmark_set('fitting_results').with_label('ic').view()\n",
      "gcf().set_size_inches((10,10))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model_appearance_1 = fa.template\n",
      "model_appearance_2 = fc.template\n",
      "model_appearance_3 = ic.template\n",
      "\n",
      "model_appearance_1.add_landmark_set('reference', {'reference': source})\n",
      "model_appearance_1.get_landmark_set('reference').with_label('reference').view()\n",
      "gcf().set_size_inches((6,6))\n",
      "\n",
      "model_appearance_2.add_landmark_set('reference', {'reference': source})\n",
      "model_appearance_2.get_landmark_set('reference').with_label('reference').view()\n",
      "gcf().set_size_inches((6,6))\n",
      "\n",
      "model_appearance_3.add_landmark_set('reference', {'reference': source})\n",
      "model_appearance_3.get_landmark_set('reference').with_label('reference').view()\n",
      "gcf().set_size_inches((6,6))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}