{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Images"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Introduction"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Images** are simply **n-dimensional** regular arrays of **pixels** where **n >= 2**. Each pixel has **k-channels** of information, and, *once instantiated*, for all images **`k >= 1`**. All pixels and all channels are of the same data type, but there is no restriction in general on what that data type is.\n",
      "\n",
      "Although there are many Image class specializations, all Images are instances of `AbstractNDImage`, and the vast majority of the functionality is shared by all images. We use the syntax \n",
      "    \n",
      "    (i, j, ...., l, [k])\n",
      "    \n",
      "To declare an image shape. The `i` is the size of the first image dimension, `j` the second. This image is of `n` dimensions - the final spatial dimension being of size `l`. The `[]` sybolizes that this is the channel axis - this image has `k` channels. A few examples for clarity:\n",
      "\n",
      "- low-resolution greyscale image: `(320, 240, [1])`\n",
      "- high-resolution RGB image: `(1700, 1650, [3])`\n",
      "- intensity voxel image: `(1024, 1024, 1024, [1])`\n",
      "\n",
      "commonly the channel has an explicit meaning - these are symbolized by a `<>`. For example:\n",
      "    \n",
      "- low-resolution greyscale image: `(320, 240, <I>)`\n",
      "- high-resolution RGB image: `(1700, 1650, <R, G, B>)`\n",
      "- depth image: `(1024, 768, <Z>)`\n",
      "\n",
      "We now use this notation to explain all of the image classes. As a final note - some classes are fixed to have only one channel. The constructors for these images don't expect you to pass a numpy array in with a dead axis on the end all the time. To signify this, the channel signature includes an exclamation mark to show it is implictly generated for you, for example\n",
      "\n",
      "- depth image: `(1024, 768, !<Z>!)` "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To aid with the explanations, lets import the good old Takeo and Lenna images. `auto_import` will always return to you the right image specialization - just use as normal"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pybug.io import auto_import\n",
      "from pybug import data_path_to\n",
      "lenna = auto_import(data_path_to('lenna*'))[0]\n",
      "takeo_rgb = auto_import(data_path_to('takeo*'))[0]\n",
      "# Takeo is RGB with repeated channels - convert to greyscale\n",
      "takeo = takeo_rgb.as_greyscale(mode='average')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'Lenna is a {}'.format(type(lenna))\n",
      "print 'Takeo is a {}'.format(type(takeo))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "AbstractNDImage"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "`(i, j, ...., n, [k])`"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "All images are `AbstractNDImage` instance, and a large bulk of functionality can be explored in this one class."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pybug.image.base import AbstractNDImage\n",
      "print \"Lenna 'isa' AbstractNDImage: {}\".format(isinstance(lenna, AbstractNDImage))\n",
      "print \"Takeo 'isa' AbstractNDImage: {}\".format(isinstance(lenna, AbstractNDImage))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**pixels**\n",
      "- The actual data of the image is stored on the `self.pixels` property. `self.pixels[..., -1]` is refered to as the *channel axis* - it is always present on an instantiated subclass of `AbstractNDImage` (even if for instance we know the number of channels to always be 1)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'Takeo shape:{}'.format(takeo.pixels.shape)  # takeo is an RGB image even though all the channels are the same\n",
      "print 'The number of channels in Takeo is {}'.format(takeo.pixels.shape[-1])\n",
      "print \"But this the right way to find out is with the 'n_channels' property: {}\".format(takeo.n_channels)\n",
      "print 'n_channels for Lenna is {}'.format(lenna.n_channels)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**shape**\n",
      "- The `self.shape` of the image is the spatial dimension of the array- that's `(i, j, ..., n)`"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'Takeo has a shape of {}'.format(takeo.shape)\n",
      "print 'Lenna has a shape of {}'.format(lenna.shape)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**width, height and depth**\n",
      "- annoyingly, images have a very a peculiar format. The `0`'th axis of pixels is the 'height' or 'y' axis, and it starts at the top of the image and runs down. The `1`'st axis is the 'width' or 'x' axis - it starts from the left of the image and runs across. In volumetric data the `2`nd axis reverts back to sensible ordering, and is known as the 'depth' or 'z' axis.  \n",
      "\n",
      "Most of the time worrying about this will lead you into hot water - it's a lot better to not get bogged down in the terminology and just consider the image as an array, just like all our other data. As a result, all our algorithms, such as gradient, will be ordered by axis `0,1,...,n` not `x,y,z` (as this would be axis `1,0,2`). The `self.shape` we printed above was the shape of the underlying array, and so was `(height, width)`. You can use the `self.width` `self.height` and `self.depth` properties to check this for yourself if you ever get confused though"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      " # note that depth is spatial - even though Lenna has 3 channels it's depth is 0\n",
      "print 'Lenna W:{} H:{} D:{}'.format(lenna.width, lenna.height, lenna.depth)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**centre**\n",
      "- returns the gemetric centre of the image, in axis ordering"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# note that this is (axis0, axis1), which is (height, width) or (Y, X)!\n",
      "print 'the centre of Takeo is {}'.format(takeo.centre)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**counts**\n",
      "- Image metrics are directly accessable as properties. Note that `n_pixels` is channel independent - to find the total size of the array (including channels) use `n_elements`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'Lenna n_dims : {}'.format(lenna.n_dims)\n",
      "print 'Lenna n_channels : {}'.format(lenna.n_channels)\n",
      "print 'Lenna n_pixels : {}'.format(lenna.n_pixels)\n",
      "print 'Lenna n_elements: {}'.format(lenna.n_elements)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**view**\n",
      "- As you'd expect, all images are viewable."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "takeo.view()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lenna.view()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "you can pass the `channel=x` to inspect a single channel of the image"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# viewing Lenna's green channel...\n",
      "lenna.view(channel=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**crop**\n",
      "- All images are cropable. There are two core crop methods: `crop()`, which is inplace, and `cropped_copy()` which returns the cropped image without damaging the instance it is called on. Both execute identical code paths. To crop we provide the minimum values per dimension where we want the crop to start, and the maximum values where we want the crop to end. For example, to crop Takeo from the centre down to the bottom corner, we could do"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "takeo_cropped = takeo.cropped_copy(takeo.centre, np.array(takeo.shape))\n",
      "takeo_cropped.view()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**rescale**\n",
      "- All images are rescalable. Simply choose the scale factor you wish to apply. For instance, to make Lena twice as big"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lenna_double = lenna.rescale(2.0)\n",
      "print lenna_double"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**landmark support**\n",
      "- All Images are landmarkable. Let's import an image that has landmarks attached"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "breakingbad = auto_import(data_path_to('breakingbad.jpg'))[0]\n",
      "breakingbad.landmarks['PTS'].view()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "breakingbad.landmarks['PTS']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "it can sometimes be useful to constrain an image to be bound around it's landmarks. A convienience method exists to do just this"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "breakingbad.crop_to_landmarks(boundary=20)\n",
      "# note that this method is smart enough to not stray outside the boundary of the image\n",
      "breakingbad.landmarks['PTS'].view()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "BooleanNDImage"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "`(i, j, ...., n, !<B>!)`"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The first concrete Image subclass we will look at is `BooleanNDImage`. This is an **n-dimensional** image with a single channel per pixel. The datatype of this image is `np.bool`. First, remember that `BooleanNDImage` is a subclass of `AbstractNDImage` and so all of the above features apply again."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pybug.image import BooleanNDImage\n",
      "random_seed = np.random.random(lenna.shape) # shape doesn't include channel - and that's what we want\n",
      "random_mask = BooleanNDImage(random_seed > 0.5)\n",
      "print \"the mask's shape is as expected: {}\".format(random_mask.shape)\n",
      "print \"the channel has been added to the mask's pixel's shape for us: {}\".format(random_mask.pixels.shape)\n",
      "random_mask.view()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Note that the constructor for the Boolean Image doesn't require you to pass in the redundant channel axis - it's created for you."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**blank()**\n",
      "- If you just want a quick all true or all false mask use the `blank()` method. You can rely on this existing on every concrete Image class."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "all_true_mask = BooleanNDImage.blank((120, 240))\n",
      "all_false_mask = BooleanNDImage.blank((120, 240), fill=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**metrics**\n",
      "- It's trivial to find out how many True and False elements there are in the mask"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'n_pixels on random_mask: {}'.format(random_mask.n_pixels)\n",
      "print 'n_true pixels on random_mask: {}'.format(random_mask.n_true)\n",
      "print 'n_false pixels on random_mask: {}'.format(random_mask.n_false)\n",
      "print 'proportion_true on random_mask: {:.3}'.format(random_mask.proportion_true)\n",
      "print 'proportion_false on random_mask: {:.3}'.format(random_mask.proportion_false)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**true_indices/false_indices** \n",
      "- In addition, `BooleanNDImage` has functionality that aids in the use of the class as a mask to another image. The indices properties give you access to the coordinates of the True and False values as if the mask had been flattened."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from copy import deepcopy\n",
      "small_amount_true = deepcopy(all_false_mask)\n",
      "small_amount_true.pixels[4, 8] = True\n",
      "small_amount_true.pixels[15, 56] = True\n",
      "small_amount_true.pixels[0, 4] = True\n",
      "print small_amount_true.true_indices # note the ordering is incremental C ordered\n",
      "print 'the shape of true indices: {}'.format(small_amount_true.true_indices.shape)\n",
      "print 'the shape of false indices: {}'.format(small_amount_true.false_indices.shape)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**all_indices**\n",
      "- For completion, you can request the indices of the whole mask"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'the shape of all indices: {}'.format(small_amount_true.all_indices.shape)\n",
      "# note that all_indices = true_indices + false_indices"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**mask**\n",
      "- if you need to directly mask another image of the same size (with an arbitriy number of channels) use the `mask` property. This is used heavily in `MaskedNDImage`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lenna_masked_pixels_flatted = lenna.pixels[random_mask.mask]\n",
      "lenna_masked_pixels_flatted.shape\n",
      "# note we can only do this as random_mask is the shape of lenna\n",
      "print 'is Lenna and random mask the same shape? {}'.format(lenna.shape == random_mask.shape)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**print**\n",
      "- often, you just want an overview of an image. Just print it to get a quick summary"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print random_mask\n",
      "print lenna\n",
      "print takeo"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "MaskedNDImage"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "`(i, j, ...., n, [k])`"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Notice in the above print statements that lenna and takeo have attached masks. This is because **all concrete image classes bar BooleanImage are instances of MaskedNDImage**. This means this functionality is available to all images we deal with directly. Just like you would expect, `MaskedNDImage`s have a mask attached to them which augments their usual behavior."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**mask**\n",
      "- all MaskedNDImages have a `BooleanNDImage` of appropriate size attached to them at the mask property. On construction, a mask can be specified at the `mask` kwarg (either a boolean `ndarray` or a `BooleanNDImage` instance). If nothing is provided, the mask is set to all true. A `MaskedNDImage` with an all true mask behaves exactly as an `AbstractNDImage`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# imported images have all-true masks on them to start with\n",
      "print takeo.mask\n",
      "takeo.mask.view()\n",
      "print breakingbad.mask"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**constrain_mask_to_landmarks**\n",
      "- this isn't actually available to all MaskedNDImages - but only to the subclass specializing in images, `Abstract2DImage` (which both `RGBImage` and `IntensityImage` are instances of). It allows us to update the mask to equal the convex hull around some landmarks on the image. You can choose a particular group of landmarks (e.g. `PTS`) and then a specific label (e.g. `perimeter`). By default, if neither are provided (and if their is only one landmark group) all the landmarks are used to form a convex hull."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "breakingbad.constrain_mask_to_landmarks()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "breakingbad.mask.view()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "breakingbad.landmarks.view()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**view behavior**\n",
      "- By default, only the masked part of a masked image is shown when viewing"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "breakingbad.view()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "use `masked=False` to see everything"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "breakingbad.view(masked=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Thanks to kwarg chaining, this can even be used when viewing landmarks"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "breakingbad.landmarks.view(channel=2, masked=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**as_vector() / from_vector() behavior**\n",
      "- `as_vector()` and `from_vector()` on `MaskedNDImage`s only returns True mask values flattened."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'breakingbad has {} pixels, but only {} are masked.'.format(breakingbad.n_pixels, breakingbad.n_true_pixels)\n",
      "print 'breakingbad has {} elements (3 x n_pixels)'.format(breakingbad.n_elements)\n",
      "vectorized_bad = breakingbad.as_vector()\n",
      "print 'vector of breaking bad is of shape {}'.format(vectorized_bad.shape)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**gradient()**\n",
      "- all masked images can calculate there own gradient - the result is always a `MaskedNDImage`. Note that landmarks from the original image are persisted to the gradient. Also the `nullify_values_at_mask_boundaries` kwarg is useful for calculating gradients with masked data that has empty regions, such as in AAM's."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "grads = breakingbad.gradient(nullify_values_at_mask_boundaries=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "grads.view(channel=3, masked=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Abstract2DImage, RGBImage, IntensityImage"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "traditional 2D images have special support in the image module, however the specialization required is very light (the whole of the `image.standard.py` module is only 256 lines). `RGBImage` and `IntensityImage` are the two concrete standard image classes for RGB and greyscale data respectively. Both are instances of Abstract2DImage, which is a direct subclass of `MaskedNDImage`. All traditional image formats that are processed from the `pybug.io` package are returned as one of these two subclasses. For instance, take a look at the iamges we have been using all along"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print type(breakingbad)\n",
      "print type(takeo)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**data validation**\n",
      "- all standard images will convert their type from np.uint to np.float64, rescaling pixel values down to be in the range 0-1."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**blank()**\n",
      "- blank specializations are straight forward"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pybug.image import RGBImage, IntensityImage\n",
      "red = RGBImage.blank((320, 240))\n",
      "red.pixels[...,0] = 1\n",
      "red.view()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**as_greyscale()**\n",
      "- `RGBImage` knows how to convert itself to a greyscale image. See the docstring for details, as a few methods of conversion are available. The default is based on luminosity, which is the same one as is used in Matlab."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "greyscale_bb = breakingbad.as_greyscale()\n",
      "print 'the as_greyscale() output has type {}'.format(type(greyscale_bb))\n",
      "print greyscale_bb\n",
      "greyscale_bb.landmarks.view() # notice how landmarks are preserved"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}